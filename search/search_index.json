{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 Tugas MataKuliah Data Mining Biodata \u00b6 Nama : Rizaldi Febri Agil Prasetya NIM : 180411100085 KELAS : Penambangan Data 5-B Program Studi : Teknik Informatika Fakultas : Teknik Perguruan Tinggi : Universitas Trunojoyo Madura Dosen Pengampu : @mulaab Referensi : https://mulaab.github.io/datamining","title":"biodata"},{"location":"#welcome","text":"Tugas MataKuliah Data Mining","title":"Welcome"},{"location":"#biodata","text":"Nama : Rizaldi Febri Agil Prasetya NIM : 180411100085 KELAS : Penambangan Data 5-B Program Studi : Teknik Informatika Fakultas : Teknik Perguruan Tinggi : Universitas Trunojoyo Madura Dosen Pengampu : @mulaab Referensi : https://mulaab.github.io/datamining","title":"Biodata"},{"location":"MengukurJaral/","text":"Pengertian \u00b6 Disini kita akan belajar cara mengukur jarak data menggunakan beberapa cara atau metode Minkowski Distance \u00b6 Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Manhattan distance \u00b6 Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ implementasi \u00b6 silahkan implementasinya Disini disana lengkap dengan codingan dan outputannya MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"mengukur jarak data"},{"location":"MengukurJaral/#pengertian","text":"Disini kita akan belajar cara mengukur jarak data menggunakan beberapa cara atau metode","title":"Pengertian"},{"location":"MengukurJaral/#minkowski-distance","text":"Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$","title":"Minkowski Distance"},{"location":"MengukurJaral/#manhattan-distance","text":"Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$","title":"Manhattan distance"},{"location":"MengukurJaral/#implementasi","text":"silahkan implementasinya Disini disana lengkap dengan codingan dan outputannya MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"implementasi"},{"location":"StatistikDesc/","text":"Ukuran Kecenderungan Terpusat \u00b6 Mean(Rata-Rata) \u00b6 Psada bagian ini, kami melihat cara untuk mengukur kecenderungan pusat data. Misalkan kita mempunyai atribut hasil pretest yang dinyatakan dengan atribut X. Misalkan x1,x2,...,xNx1,x2,...,xN menjadi himpunan nilai N yang diamati atau pengamatan untuk X. Di sini, nilai-nilai ini juga dapat disebut set data (untuk X). Jika kita merencanakan pengamatan untuk nilai pretest, di mana sebagian besar nilai berada? Ini memberi kita gambaran tentang kecenderungan pusat dari data. Ukuran kecenderungan pusat data ukurannya adalah rata-rata(mean), median, modus (mode), dan midrange. Atribut numerik yang paling umum dan efektif dari \"pusat\" dari set data adalah mean (aritmatika). Misalkan x1,x2,...,xNx1,x2,...,xN menjadi satu set nilai N atau pengamatan, Rata-rata dari nilai pretes dinyatakan dengan $$ \\bar{x}=\\frac{\\sum_{i=1}^{N} x_{i}}{N}=\\frac{x_{1}+x_{2}+\\cdots+x_{N}}{N} $$ `` Kadang-kadang, setiap nilai xixi dalam satu data dapat dikaitkan dengan bobot wiwi untuk i=1,..,Ni=1,..,N. Bobot tersebut mencerminkan signifikansi, kepentingan, atau frekuensi kejadian yang melekat pada masing masing nilai. Dalam hal ini, kita dapat menghitungnya dengan $$ \\overline{x}=\\frac{\\sum_{i=1}^{N} w_{i} x_{i}}{\\sum_{i=1}^{N} w_{i}}=\\frac{w_{1} x_{1}+w_{2} x_{2}+\\cdots+w_{N} x_{N}}{w_{1}+w_{2}+\\cdots+w_{N}} $$ Meskipun rata-rata adalah jumlah yang sangat berguna untuk menggambarkan kumpulan data, itu tidak selalu cara terbaik untuk mengukur pusat data. Masalah utama dengan mean adalah sensitivitasnya terhadap nilai ekstrim (mis., outlier). Bahkan beberapa nilai ekstrem saja dapat merusak mean. Misalnya, gaji rata-rata di suatu perusahaan mungkin sangat besar didorong oleh beberapa manajer bergaji tinggi. Demikian pula, nilai rata-rata kelas di ujian dapat rata-rata rendah karena beberapa ada beberap skor nilai saja yang sangat rendah. Untuk mengimbangi efek tersebut kita bisa menggunakan rata-rata yang dipangkas (trimmed mean), yang merupakan rata-rata yang diperoleh setelah memangkas nilai paling tinggi dan nilai yang paling rendah. Untuk contoh, kita dapat mengurutkan nilai gaji yang diamati kemudian menghapus 2% atas dan bawah nilai tersebut sebelum menghitung mean. Kita harus menghindari pemotongan bagian yang terlalu besar (seperti 20%) pada kedua ujungnya, karena hal ini dapat mengakibatkan hilangnya informasi yang berharga) Median (Nilai Tengah) \u00b6 Untuk data miring (asimetris), ukuran pusat data yang lebih baik adalah median, yang merupakan nilai tengah dalam satu set nilai data yang diurutkan. Ini adalah nilai yang memisahkan separuh data yang lebih tinggi dari data tersebut dan sebagian data yang lebih rendah dari data tersebut. Dalam probabilitas dan statistik, median umumnya berlaku untuk data numerik; namun, kami dapat memperluas konsep menjadi data ordinal. Misalkan kumpulan N data yang diberikan untuk atribut X diurutkan dalam urutan naik. Jika N ganjil, maka median adalah nilai tengah dari data yang ordinal. Jika N adalah genap, maka mediannya tidak unik; dihitung dengan rata rata dari nilai $$(\\frac{N}{2}+1) +(\\frac{N}{2}-1) $$ Namun pada data berkelompok, dengan data yang berbentuk kelas interval, kita tidak bisa langsung mengetahui nilai median jika kelas mediannya sudah diketahui dengan formula $$ M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p $$ $$ \\begin{array}{l}{M e=\\text { median }} \\ {x_{i j}=\\text { batas bawah median }} \\ {n=\\text { jumlah data }} \\ {f_{k i j}=\\text { frekuensi kumulatif data di bawah kelas median }} \\ {f_{i}=\\text { frekuensi data pada kelas median }} \\ {p=\\text { panjang interval kelas }}\\end{array} $$ Rentang (Range), Quartil, and Rentang Interquartile \u00b6 \u00b6 Misalkan x1,x2,..xNx1,x2,..xN adalah sekumpulan pengamatan untuk atribut numerik, XX. Rentang adalah selisih antara nilai terbesar (maks ()) dan terkecil (min ()). Misalkan data untuk atribut X diurutkan dalam urutan naik.Bagilah data berdasarkan titik titik tertentu sehingga membagi distribusi data ukuran yang sama, seperti pada Gambar dibawah. Titik data ini disebut kuantil. 2-quantile adalah titik data yang membagi bagian bawah dan atas dari distribusi data. Ini sama dengan median. 4-kuantil adalah tiga titik data yang membagi distribusi data menjadi empat bagian yang sama; setiap bagian mewakili seperempat dari distribusi data. Ini lebih sering disebut sebagai kuartil. 100-kuantil lebih sering disebut sebagai persentil; mereka membagi distribusi data menjadi 100 data berukuran sama. Median, kuartil, dan persentil adalah bentuk kuantil yang paling banyak digunakan. Kuartil memberikan gambaran pusat distribus, penyebaran, dan bentuk distribusi. Kuartil satu, dilambangkan oleh Q1, adalah persentil ke-25. Nilai ini menunjukan 25% terendah dari data. Kuartil ketiga, dilambangkan oleh Q3, adalah persentil ke-75 - itu memisahkan data 75% dari terendah data (atau 25% dari tertinggi data. Kuartil kedua adalah persentil ke-50 atau median dari distribusi data. Variansi dan Standar Deviasi \u00b6 \u00b6 Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar. Varian dari pengamatan $$ N, x_1, x_2, ..., x_N $$ untuk atribut numerik X adalah $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$ Skewness \u00b6 \u00b6 Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut $$ s k=\\frac{\\overline{X}-M o}{s} $$ dengan $$ \\overline{X}-M o \\approx 3(\\overline{X}-M e) $$ maka $$ s k \\approx \\frac{3(\\overline{X}-M e)}{s} $$ implementasi \u00b6 \u00b6 silahkan download filenya disini import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = ';' ) temp = { 'stats' :[ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile1' , 'Quartile2' , 'Quartile3' , 'Median' , 'Modus' ]} for i in df . columns : temp [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), df [ i ] . std (), df [ i ] . var (), df [ i ] . skew (), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] file = pd . DataFrame ( temp ) file . style . hide_index () stats x1 x2 Min 2 500 Max 3 1000 Mean 2.66667 700 Standard Deviasi 0.57735 264.575 Variasi 0.333333 70000 Skewness -1.73205 1.45786 Quartile 1 2.5 550 Quartile 2 3 600 Quartile 3 3 800 Median 2.66667 700 Modus 3 500 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"statistik deskriptif"},{"location":"StatistikDesc/#ukuran-kecenderungan-terpusat","text":"","title":"Ukuran Kecenderungan Terpusat"},{"location":"StatistikDesc/#meanrata-rata","text":"Psada bagian ini, kami melihat cara untuk mengukur kecenderungan pusat data. Misalkan kita mempunyai atribut hasil pretest yang dinyatakan dengan atribut X. Misalkan x1,x2,...,xNx1,x2,...,xN menjadi himpunan nilai N yang diamati atau pengamatan untuk X. Di sini, nilai-nilai ini juga dapat disebut set data (untuk X). Jika kita merencanakan pengamatan untuk nilai pretest, di mana sebagian besar nilai berada? Ini memberi kita gambaran tentang kecenderungan pusat dari data. Ukuran kecenderungan pusat data ukurannya adalah rata-rata(mean), median, modus (mode), dan midrange. Atribut numerik yang paling umum dan efektif dari \"pusat\" dari set data adalah mean (aritmatika). Misalkan x1,x2,...,xNx1,x2,...,xN menjadi satu set nilai N atau pengamatan, Rata-rata dari nilai pretes dinyatakan dengan $$ \\bar{x}=\\frac{\\sum_{i=1}^{N} x_{i}}{N}=\\frac{x_{1}+x_{2}+\\cdots+x_{N}}{N} $$ `` Kadang-kadang, setiap nilai xixi dalam satu data dapat dikaitkan dengan bobot wiwi untuk i=1,..,Ni=1,..,N. Bobot tersebut mencerminkan signifikansi, kepentingan, atau frekuensi kejadian yang melekat pada masing masing nilai. Dalam hal ini, kita dapat menghitungnya dengan $$ \\overline{x}=\\frac{\\sum_{i=1}^{N} w_{i} x_{i}}{\\sum_{i=1}^{N} w_{i}}=\\frac{w_{1} x_{1}+w_{2} x_{2}+\\cdots+w_{N} x_{N}}{w_{1}+w_{2}+\\cdots+w_{N}} $$ Meskipun rata-rata adalah jumlah yang sangat berguna untuk menggambarkan kumpulan data, itu tidak selalu cara terbaik untuk mengukur pusat data. Masalah utama dengan mean adalah sensitivitasnya terhadap nilai ekstrim (mis., outlier). Bahkan beberapa nilai ekstrem saja dapat merusak mean. Misalnya, gaji rata-rata di suatu perusahaan mungkin sangat besar didorong oleh beberapa manajer bergaji tinggi. Demikian pula, nilai rata-rata kelas di ujian dapat rata-rata rendah karena beberapa ada beberap skor nilai saja yang sangat rendah. Untuk mengimbangi efek tersebut kita bisa menggunakan rata-rata yang dipangkas (trimmed mean), yang merupakan rata-rata yang diperoleh setelah memangkas nilai paling tinggi dan nilai yang paling rendah. Untuk contoh, kita dapat mengurutkan nilai gaji yang diamati kemudian menghapus 2% atas dan bawah nilai tersebut sebelum menghitung mean. Kita harus menghindari pemotongan bagian yang terlalu besar (seperti 20%) pada kedua ujungnya, karena hal ini dapat mengakibatkan hilangnya informasi yang berharga)","title":"Mean(Rata-Rata)"},{"location":"StatistikDesc/#median-nilai-tengah","text":"Untuk data miring (asimetris), ukuran pusat data yang lebih baik adalah median, yang merupakan nilai tengah dalam satu set nilai data yang diurutkan. Ini adalah nilai yang memisahkan separuh data yang lebih tinggi dari data tersebut dan sebagian data yang lebih rendah dari data tersebut. Dalam probabilitas dan statistik, median umumnya berlaku untuk data numerik; namun, kami dapat memperluas konsep menjadi data ordinal. Misalkan kumpulan N data yang diberikan untuk atribut X diurutkan dalam urutan naik. Jika N ganjil, maka median adalah nilai tengah dari data yang ordinal. Jika N adalah genap, maka mediannya tidak unik; dihitung dengan rata rata dari nilai $$(\\frac{N}{2}+1) +(\\frac{N}{2}-1) $$ Namun pada data berkelompok, dengan data yang berbentuk kelas interval, kita tidak bisa langsung mengetahui nilai median jika kelas mediannya sudah diketahui dengan formula $$ M e=x_{i j}+\\left(\\frac{\\frac{n}{2}-f_{k i j}}{f_{i}}\\right) p $$ $$ \\begin{array}{l}{M e=\\text { median }} \\ {x_{i j}=\\text { batas bawah median }} \\ {n=\\text { jumlah data }} \\ {f_{k i j}=\\text { frekuensi kumulatif data di bawah kelas median }} \\ {f_{i}=\\text { frekuensi data pada kelas median }} \\ {p=\\text { panjang interval kelas }}\\end{array} $$","title":"Median (Nilai Tengah)"},{"location":"StatistikDesc/#rentang-range-quartil-and-rentang-interquartile","text":"Misalkan x1,x2,..xNx1,x2,..xN adalah sekumpulan pengamatan untuk atribut numerik, XX. Rentang adalah selisih antara nilai terbesar (maks ()) dan terkecil (min ()). Misalkan data untuk atribut X diurutkan dalam urutan naik.Bagilah data berdasarkan titik titik tertentu sehingga membagi distribusi data ukuran yang sama, seperti pada Gambar dibawah. Titik data ini disebut kuantil. 2-quantile adalah titik data yang membagi bagian bawah dan atas dari distribusi data. Ini sama dengan median. 4-kuantil adalah tiga titik data yang membagi distribusi data menjadi empat bagian yang sama; setiap bagian mewakili seperempat dari distribusi data. Ini lebih sering disebut sebagai kuartil. 100-kuantil lebih sering disebut sebagai persentil; mereka membagi distribusi data menjadi 100 data berukuran sama. Median, kuartil, dan persentil adalah bentuk kuantil yang paling banyak digunakan. Kuartil memberikan gambaran pusat distribus, penyebaran, dan bentuk distribusi. Kuartil satu, dilambangkan oleh Q1, adalah persentil ke-25. Nilai ini menunjukan 25% terendah dari data. Kuartil ketiga, dilambangkan oleh Q3, adalah persentil ke-75 - itu memisahkan data 75% dari terendah data (atau 25% dari tertinggi data. Kuartil kedua adalah persentil ke-50 atau median dari distribusi data.","title":"Rentang (Range), Quartil, and Rentang Interquartile\u00b6"},{"location":"StatistikDesc/#variansi-dan-standar-deviasi","text":"Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar. Varian dari pengamatan $$ N, x_1, x_2, ..., x_N $$ untuk atribut numerik X adalah $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$","title":"Variansi dan Standar Deviasi\u00b6"},{"location":"StatistikDesc/#skewness","text":"Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut $$ s k=\\frac{\\overline{X}-M o}{s} $$ dengan $$ \\overline{X}-M o \\approx 3(\\overline{X}-M e) $$ maka $$ s k \\approx \\frac{3(\\overline{X}-M e)}{s} $$","title":"Skewness\u00b6"},{"location":"StatistikDesc/#implementasi","text":"silahkan download filenya disini import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = ';' ) temp = { 'stats' :[ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile1' , 'Quartile2' , 'Quartile3' , 'Median' , 'Modus' ]} for i in df . columns : temp [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), df [ i ] . std (), df [ i ] . var (), df [ i ] . skew (), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] file = pd . DataFrame ( temp ) file . style . hide_index () stats x1 x2 Min 2 500 Max 3 1000 Mean 2.66667 700 Standard Deviasi 0.57735 264.575 Variasi 0.333333 70000 Skewness -1.73205 1.45786 Quartile 1 2.5 550 Quartile 2 3 600 Quartile 3 3 800 Median 2.66667 700 Modus 3 500 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"implementasi\u00b6"},{"location":"featureselection/","text":"Feature Selection \u00b6 \u200b Feature Selection atau seleksi fitur adalah sebuah proses yang biasa digunakan pada Machine Learning dimana sekumpulan dari fitur yang dimiliki oleh data digunakan untuk pembelajaran algoritma. Feature selection menurut Oded Maimon [12] telah menjadi bidang penelitian aktif dalam pengenalan pola, statistik, dan Data Mining. \u200b Ide utama dari Feature Selection adalah memilih subset dari fitur yang ada tanpa transformasi karena tidak semua fitur/atribut relevan dengan masalah. Bahkan beberapa dari fitur atau atribut tersebut mengganggu dan mengurangi akurasi. Noisy Features atau fitur yang tidak terpakai tersebut harus dihapus untuk meningkatkan akurasi. Selain itu dengan fitur atau atribut yang sangatbanyak akan memperlambat proses komputasi. program feature selection \u00b6 from pandas import * from IPython.display import HTML , display from tabulate import tabulate from math import log from sklearn.feature_selection import mutual_info_classif def table ( df ): display ( HTML ( tabulate ( df , tablefmt = 'html' , headers = 'keys' , showindex = False ))) df = read_csv ( 'data.csv' , usecols = [ 0 , 1 , 2 , 3 , 4 ], sep = ';' ) table ( df ) berikut hasil beberapa sample yang telah kita tentukan sebelumnya \u00b6 outlook temperature humidity windy play sunny hot high False no sunny hot high True no overcast hot high False yes rainy mild high False yes rainy cool normal False yes rainy cool normal True no overcast cool normal True yes sunny mild high False no sunny cool normal False yes rainy mild normal False yes sunny mild normal True yes overcast mild high True yes overcast hot normal False yes rainy mild high True no Entropy \u00b6 \u200b entropy adalah sebuah kolom yang mengandung nilai-nilai bersih dari sebuah banyaknya kolom, entropy ini biasanya merupakan kolom yang mewakili pernytaan-pernyataan dari semua kolom Rumus : \u00b6 $$ E(T) = \\sum_{i=1}^n {-P_i\\log{P_i}} $$ $$ P = merupakan~ probability~ yang ~mucul~ dalam ~row $$ def findEntropy ( column ): rawGroups = df . groupby ( column ) targetGroups = [[ key , len ( data ), len ( data ) / df [ column ] . size ] for key , data in rawGroups ] targetGroups = DataFrame ( targetGroups , columns = [ 'value' , 'count' , 'probability' ]) return sum ([ - x * log ( x , 2 ) for x in targetGroups [ 'probability' ]]), targetGroups , rawGroups entropyTarget , groupTargets , _ = findEntropy ( 'play' ) table ( groupTargets ) print ( 'entropy target =' , entropyTarget ) hasil tabel dari entropy dari yang sudah kita cari \u00b6 value count probability no 5 0.357143 yes 9 0.642857 Hasil entropy \u00b6 entropy target = 0.9402859586706309 Gain \u00b6 \u200b merupakan sebuah fitur yang berada dalam sebuah data Rumus mencari Gain: \u00b6 $$ \\operatorname{Gain}(T, X) = \\operatorname{Entropy}(T) - \\sum_{v\\in{T}} \\frac{T_{X,v}}{T} E(T_{X,v}) $$ Program \u00b6 def findGain ( column ): entropyOutlook , groupOutlooks , rawOutlooks = findEntropy ( column ) table ( groupOutlooks ) gain = entropyTarget - sum ( len ( data ) / len ( df ) * sum ( - x / len ( data ) * log ( x / len ( data ), 2 ) for x in data . groupby ( 'play' ) . size ()) for key , data in rawOutlooks ) print ( \"gain of\" , column , \"is\" , gain ) return gain gains = [[ x , findGain ( x )] for x in [ 'outlook' , 'temperature' , 'humidity' , 'windy' ]] Outlook value count probability overcast 4 0.285714 rainy 5 0.357143 sunny 5 0.357143 gain of outlook is 0.2467498197744391 Temperature value count probability cool 4 0.285714 hot 4 0.285714 mild 6 0.428571 gain of temperature is 0.029222565658954647 Humidity value count probability high 7 0.5 normal 7 0.5 gain of humidity is 0.15183550136234136 Windy value count probability False 8 0.571429 True 6 0.428571 gain of windy is 0.04812703040826927 Program menyatukan semua Gain: \u00b6 table ( DataFrame ( gains , columns = [ \"Feature\" , \"Gain Score\" ]) . sort_values ( \"Gain Score\" )[:: - 1 ]) Feature Gain Score outlook 0.24675 humidity 0.151836 windy 0.048127 temperature 0.0292226 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"feature selection"},{"location":"featureselection/#feature-selection","text":"\u200b Feature Selection atau seleksi fitur adalah sebuah proses yang biasa digunakan pada Machine Learning dimana sekumpulan dari fitur yang dimiliki oleh data digunakan untuk pembelajaran algoritma. Feature selection menurut Oded Maimon [12] telah menjadi bidang penelitian aktif dalam pengenalan pola, statistik, dan Data Mining. \u200b Ide utama dari Feature Selection adalah memilih subset dari fitur yang ada tanpa transformasi karena tidak semua fitur/atribut relevan dengan masalah. Bahkan beberapa dari fitur atau atribut tersebut mengganggu dan mengurangi akurasi. Noisy Features atau fitur yang tidak terpakai tersebut harus dihapus untuk meningkatkan akurasi. Selain itu dengan fitur atau atribut yang sangatbanyak akan memperlambat proses komputasi.","title":"Feature Selection"},{"location":"featureselection/#program-feature-selection","text":"from pandas import * from IPython.display import HTML , display from tabulate import tabulate from math import log from sklearn.feature_selection import mutual_info_classif def table ( df ): display ( HTML ( tabulate ( df , tablefmt = 'html' , headers = 'keys' , showindex = False ))) df = read_csv ( 'data.csv' , usecols = [ 0 , 1 , 2 , 3 , 4 ], sep = ';' ) table ( df )","title":"program feature selection"},{"location":"featureselection/#berikut-hasil-beberapa-sample-yang-telah-kita-tentukan-sebelumnya","text":"outlook temperature humidity windy play sunny hot high False no sunny hot high True no overcast hot high False yes rainy mild high False yes rainy cool normal False yes rainy cool normal True no overcast cool normal True yes sunny mild high False no sunny cool normal False yes rainy mild normal False yes sunny mild normal True yes overcast mild high True yes overcast hot normal False yes rainy mild high True no","title":"berikut hasil beberapa sample yang telah kita tentukan sebelumnya"},{"location":"featureselection/#entropy","text":"\u200b entropy adalah sebuah kolom yang mengandung nilai-nilai bersih dari sebuah banyaknya kolom, entropy ini biasanya merupakan kolom yang mewakili pernytaan-pernyataan dari semua kolom","title":"Entropy"},{"location":"featureselection/#rumus","text":"$$ E(T) = \\sum_{i=1}^n {-P_i\\log{P_i}} $$ $$ P = merupakan~ probability~ yang ~mucul~ dalam ~row $$ def findEntropy ( column ): rawGroups = df . groupby ( column ) targetGroups = [[ key , len ( data ), len ( data ) / df [ column ] . size ] for key , data in rawGroups ] targetGroups = DataFrame ( targetGroups , columns = [ 'value' , 'count' , 'probability' ]) return sum ([ - x * log ( x , 2 ) for x in targetGroups [ 'probability' ]]), targetGroups , rawGroups entropyTarget , groupTargets , _ = findEntropy ( 'play' ) table ( groupTargets ) print ( 'entropy target =' , entropyTarget )","title":"Rumus :"},{"location":"featureselection/#hasil-tabel-dari-entropy-dari-yang-sudah-kita-cari","text":"value count probability no 5 0.357143 yes 9 0.642857","title":"hasil tabel dari entropy dari yang sudah kita cari"},{"location":"featureselection/#hasil-entropy","text":"entropy target = 0.9402859586706309","title":"Hasil entropy"},{"location":"featureselection/#gain","text":"\u200b merupakan sebuah fitur yang berada dalam sebuah data","title":"Gain"},{"location":"featureselection/#rumus-mencari-gain","text":"$$ \\operatorname{Gain}(T, X) = \\operatorname{Entropy}(T) - \\sum_{v\\in{T}} \\frac{T_{X,v}}{T} E(T_{X,v}) $$","title":"Rumus mencari Gain:"},{"location":"featureselection/#program","text":"def findGain ( column ): entropyOutlook , groupOutlooks , rawOutlooks = findEntropy ( column ) table ( groupOutlooks ) gain = entropyTarget - sum ( len ( data ) / len ( df ) * sum ( - x / len ( data ) * log ( x / len ( data ), 2 ) for x in data . groupby ( 'play' ) . size ()) for key , data in rawOutlooks ) print ( \"gain of\" , column , \"is\" , gain ) return gain gains = [[ x , findGain ( x )] for x in [ 'outlook' , 'temperature' , 'humidity' , 'windy' ]] Outlook value count probability overcast 4 0.285714 rainy 5 0.357143 sunny 5 0.357143 gain of outlook is 0.2467498197744391 Temperature value count probability cool 4 0.285714 hot 4 0.285714 mild 6 0.428571 gain of temperature is 0.029222565658954647 Humidity value count probability high 7 0.5 normal 7 0.5 gain of humidity is 0.15183550136234136 Windy value count probability False 8 0.571429 True 6 0.428571 gain of windy is 0.04812703040826927","title":"Program"},{"location":"featureselection/#program-menyatukan-semua-gain","text":"table ( DataFrame ( gains , columns = [ \"Feature\" , \"Gain Score\" ]) . sort_values ( \"Gain Score\" )[:: - 1 ]) Feature Gain Score outlook 0.24675 humidity 0.151836 windy 0.048127 temperature 0.0292226 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Program menyatukan semua Gain:"}]}